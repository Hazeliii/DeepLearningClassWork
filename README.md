# DeepLearningClassWork
深度学习课程学了tf2,做了一些小小的作业，保存下来以供参考


## WORK1
### 1.1 掌握使用 TensorFlow 2.X 提供的接口进行训练的方法，实现通过调用高级 API 的方式进行三次函数拟合的全部流程。
![image](https://user-images.githubusercontent.com/53303848/129329077-7b91cc18-0538-40de-8407-dcaf74338ff9.png)

### 1.2 掌握 TensorFlow 2.X 自定义训练方法，实现通过自定义循环的方式进行三次函数拟合的全部流程(1.自定义循环；2.Gradient Tapes；3.AutoGraph 机制)
![image](https://user-images.githubusercontent.com/53303848/129329379-cfcdea1e-68ff-4e64-ac7e-8d176e9ac205.png)

### 1.3 掌握 TensorFlow 2.X 提供的模型断点保存方法，在任务一的基础上，使用回调函数的方式，进行对模型的保存与读取。
1.模型存储；
2.采用回调函数保存模型；
3.采用回调函数恢复模型。
![image](https://user-images.githubusercontent.com/53303848/129329537-f42add07-16fb-4894-ad36-ac1178867917.png)

### 1.4 掌握使用 TensorFlow 2.X 提供的一般模型保存方法，在任务二的基础上，使用一般模式，进行对模型的保存与读取。
1.一般保存方法；
2.保存和恢复权重；
3.保存和恢复整个模型。

## WORK2
### 训练神经网络加法器.该加法器输入为一对MNIST手写字符，输出为这两个字符所代表数字之和。
1.MNIST数据集的读取和使用；
2.tf.data.Dataset数据集的制作及使用；
3.tf.keras自定义层的方法；
4.参数共享连体网络的构建方法
![image](https://user-images.githubusercontent.com/53303848/129329892-dd05bbdf-31ab-4a10-b08a-d40969bc1ab5.png)

## WORK3
### 构建SEblock Lenet，并可视化其中的特征图、特征向量
观察每类的特征向量特点，例如比较容易混的类型的特征对比？及叠加卷积特征反映出的空间上的激活频率分布。
思考SeBlock的权重对卷积特征的影响。
1.SEblock Lenet构建和使用方法，2.特征提取方法。
![image](https://user-images.githubusercontent.com/53303848/129330303-d6582476-2ad3-41ed-9a18-5cc59cc47a33.png)
![image](https://user-images.githubusercontent.com/53303848/129330386-25e2adee-e4a6-4b34-872d-8601e9b2109c.png)

## WORK4
### 编写一个具有类似”人脸识别”功能的网络。该网络输入为两个MNIST图片，输出为两张图片的特征距离。后续处理可以根据该特征距离是否大于或小于阈值判断这两张图片是否为同一个数字(标签0)或来自不同数字(标签1)。要求构建并训练模型，最终在测试环节，在给定的数据平衡测试集上取得AUC>0.97的结果。

本任务有300s时间限制，内存限制2G，建议大家先在自己本地机器上调试好。
1. 采样数据平衡batch进行训练; 2.构建Siamese网络; 3. 定义特征距离及损失函数; 4. 评价指标；5. 梯度爆炸问题
#### 数据：
良好的机器学习模型应该能有效学习任务的数据分布。”人脸识别”中对于任务的要求不同，学习方式也会不同。如果我们要求同样低的认假率和拒真率。那么就需要测试集中，正例（同一数字，不同图片），反例（不同数字图片）的样本比例基本一致。并且样本涵盖不同数字的情况要尽量均匀。

因此，我们测试使用一个平衡测试集（正例和反例个数类似，正例和反例中，不同数字的采样比例也近似）。具体测试集设计中：（1）正例（同一数字对）8000个、反例（不同数字对）9000个。（2）正例中，10个数字类型各占1/10，800个。反例中，不同数字对的所有组合共C^2_10=45种，要求比例也为相同，即反例中，45种组合每个组合比例为1/45，200个。

我们讲过，训练、测试的数据分布要尽量一致。如果训练分布和测试分布差异很大，可能很难学习到期望的测试分布。如果要对平衡的测试集有良好的效果，训练的数据集，也应该是平衡且均匀的。请参考测试集的数据分布，设计相应的训练数据平衡采样方法：make_batch，使得每个batch都能尽量实现平衡均匀采样。整个训练过程中，正、负样本对都要出现的差不多。而且对于10个数字的正样本对，和各种不同类型（例：（0，1），（2，4）。。。共C^2_10=45种）的负样本，都要有充分的训练。

![image](https://user-images.githubusercontent.com/53303848/129330845-7d00dfb6-bf57-4096-9526-1b04bddc3fa5.png)
![image](https://user-images.githubusercontent.com/53303848/129330977-df40b6f4-9de3-490f-850f-6b505c9f1d55.png)

## WORK5
### 编写一个能描绘图像指定区域的DeepDream算法。
1.DeepDream基本算法，2.面向选定神经元的代价函数设计，3.限定图像区域的梯度求解，4.多尺度融合。
![image](https://user-images.githubusercontent.com/53303848/129331355-9f93c840-bba6-4d14-b2fe-6bc95a15c2ee.png)

![image](https://user-images.githubusercontent.com/53303848/129331487-0e3bf351-b73a-462a-911e-9cd670f64612.png)

## WORK6
### 用mobilenetV2的底层网络作为迁移学习的基础结构，通过自定义上层模型结构，设计合理的训练策略，在MNIST数据集训练网络，实现5个echo达到0.7以上的验证精度。
结合课程学习迁移学习、以及训练优化方法、学习率、正则化化方法、优化器知识等，实现合理的上层模型结构及训练策略。

提示：
时限300s，上层模型不要搞太复杂。
内存限制，batch_size不要超过512。64-256差不多。
训练策略一开始别搞太复杂，先找到合适的优化器学习率配置，等再慢慢调整

提示，在右侧编辑器补充代码，实现相应的迁移网络上层结构及训练策略，在训练测试中达到测试要求。
测试说明
测试时，第5个echo的验证精度val_accuracy>0.7
